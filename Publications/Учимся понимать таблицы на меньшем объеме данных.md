Задача распознавания [семантического следования](https://en.wikipedia.org/wiki/Textual_entailment) (textual entailment), или импликации (natural language inference), в текстах на естественном языке состоит в определении того, может ли часть текста (посылка, антецедент) подразумеваться или противоречить (или не противоречить) другому фрагменту текста (следствию, консеквенту). Хотя эта проблема часто считается важным тестом на понимание в системах машинного обучения (ML) и была глубоко изучена для простых текстов, гораздо меньше усилий было приложено для применения таких моделей к структурированным данным, таким как веб-сайты, таблицы, базы данных и т. д. Тем не менее, распознавание семантического следования особенно актуально, когда содержимое таблицы необходимо точно суммировать и представить пользователю, и важно для таких приложений, где необходима высокая точность: в [вопросно-ответных системах](https://en.wikipedia.org/wiki/Question_answering) и [виртуальных ассистентах](https://en.wikipedia.org/wiki/Virtual_assistant).

В статье «[Understanding tables with intermediate pre-training](https://www.aclweb.org/anthology/2020.findings-emnlp.27/)», опубликованной в [материалах EMNLP 2020](https://2020.emnlp.org/papers/findings), авторы представили первые методы предварительного обучения, адаптированные для анализа таблиц и позволяющие моделям учиться лучше, быстрее и на меньшем объеме данных. Авторы основываются на своей более ранней модели [TAPAS](https://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html), которая была расширением двунаправленной модели на основе [Трансформера](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html) [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) со специальными эмбеддингами для поиска ответов в таблицах. Новые методы предварительного обучения на TAPAS позволяют получить лучшие метрики на нескольких наборах данных, включающих таблицы. В [TabFact](https://tabfact.github.io/), например, сокращается разрыв между результатами выполнения этого задания моделью и человеком примерно на 50%. Авторы также систематически тестируют методы выбора подходящих входных данных для повышения эффективности, что позволяет достичь четырёхкратного увеличения скорости и снижения объема затрачиваемой памяти при сохранении 92% результатов. Все модели для разных задач и размеров выпущены в [репозитории GitHub](https://github.com/google-research/tapas), где их можно опробовать в [Colab-ноутбуке](http://tiny.cc/tapas-tabfact-colab).

# Семантическое следование

Задача семантического следования более сложна при применении к табличным данным, чем к обычному тексту. Рассмотрим, например, таблицу из Википедии и несколько предложений, связанных с содержанием таблицы. Оценка того, следует ли предложение из данных таблицы или противоречит им, может потребовать просмотра нескольких столбцов и строк и, возможно, выполнения простых числовых вычислений, таких как усреднение, суммирование, дифференцирование и т. д.

![image5](https://habrastorage.org/webt/y1/b0/ni/y1b0nia9oo165s_dprvkwu6xtes.png)

*Таблица вместе с несколькими предложениями из [TabFact](https://tabfact.github.io/). Содержание таблицы может быть использовано для подтверждения или опровержения предложения.*

На основе методов, используемых TAPAS, содержимое предложения и таблицы кодируются вместе, а затем пропускается через модель Трансформера, после чего получается вероятность того, что предложение следует или противоречит таблице.

![TAPAS](https://habrastorage.org/webt/wn/no/rn/wnnornqjoxbhoywfjpfqyj6aaqw.jpeg)

*Архитектура [модели TAPAS](https://www.aclweb.org/anthology/2020.acl-main.398) использует модель BERT для кодирования предложения и плоской таблицы, считываемой строка за строкой. Для кодирования структуры таблицы используются специальные эмбеддинги. Векторный вывод первого токена используется для прогнозирования вероятности семантического следования.*

Поскольку единственная информация в обучающих примерах — это двоичное значение (т.е. «правильно» или «неправильно»), обучение модели для понимания того, присутствует ли в предложении семантическое следование, является нетривиальной задачей. Это в очередной раз подтверждает сложность достижения генерализации в глубоком обучении, особенно в случае достаточно скудных средств выражения необходимого значения в обучающих данных. Видя отдельные предполагаемые или опровергнутые примеры, модель может легко уловить ложные закономерности в данных. Например, в предложении «Greg Norman and Billy Mayfair tie in rank» («Грег Норман и Билли Мейфэр занимают равное положение») модель может выделить слово «tie» («галстук»/«связывать», «разделять») вместо истинного сравнение положения Нормана и Мейфэра, необходимого для успешного применения модели за пределами исходных обучающих данных.

# Методы предварительного обучения

Предварительное обучение можно использовать для «прогрева» моделей, предоставляя им большие объемы легко доступных неразмеченных данных. Однако предварительное обучение обычно включает в себя в основном простой текст, а не табличные данные. Фактически, TAPAS изначально был предварительно обучен с использованием простой задачи маскированного языкового моделирования, которая не предназначалась для приложений с табличными данными. Чтобы улучшить результаты модели для табличных данных, авторы представили две новые задачи бинарной классификации предварительного обучения: контрфактическую (counterfactual) и синтетическую (synthetic). Эти задачи могут применяться в качестве второго этапа предварительного обучения (часто называемого промежуточным предварительным обучением - intermediate pre-training).

В контрфактической задаче авторы используют предложения из Википедии, в которых упоминается сущность (человек, место или предмет), которая также появляется в данной таблице. Затем в половине предложений  сущности заменяются на альтернативные. Чтобы убедиться, что утверждение реалистично, мы выбираем замену среди сущностей в том же столбце таблицы. Модель обучается распознавать, было ли изменено утверждение или нет. Эта задача предварительного обучения включает в себя миллионы таких примеров, и, хотя их интерпретация не так уж сложна, они, как правило, все равно будут звучать естественно.

Для синтетической задачи авторы используют метод, схожий с [семантическим анализом](https://www.aclweb.org/anthology/P15-1129/), в котором генерируются инструкции с использованием простого набора грамматик, требующих от модели понимания основных математических операций, таких как суммы и средние значения (например, «сумма доходов»), или знания того, как фильтровать элементы таблицы с помощью некоторого условия (например, «страна - Австралия»). Хотя эти предложения являются искусственными, они помогают модели улучшить навыки числовой и логической интерпретации.

![image1](https://habrastorage.org/webt/kh/ga/aj/khgaajbttacen6lpcd-oy3bu2_m.png)

*Примеры данных для двух новых задач предварительного обучения. **Контрфактические** примеры меняют сущности, упомянутые в предложении, которое сопровождает входную таблицу, на правдоподобную альтернативу. В **синтетических** предложениях используются правила грамматики для создания новых предложений, которые требуют сложного комбинирования информации из таблицы.*

# Результаты

Авторы оценивают успешность контрфактического и синтетического методов предварительного обучения на наборе данных TabFact, сравнивая с базовой моделью TAPAS и двумя предыдущими моделями, которые показали хорошие результаты в области семантического следования, [LogicalFactChecker](https://www.aclweb.org/anthology/2020.acl-main.539/) (LFC) и [Structure Aware Transformer](https://www.aclweb.org/anthology/2020.emnlp-main.126/) (SAT). Базовая модель TAPAS демонстрирует более высокие метрики по сравнению с LFC и SAT, но предварительно обученная модель (TAPAS + CS) работает значительно лучше, достигая наивысших метрик.

Авторы также применили TAPAS + CS для вопросно-ответных задач на [наборе данных SQA](https://www.microsoft.com/en-us/download/details.aspx?id=54253), для которого модель  должна находить ответы из содержимого таблиц в формате диалога. Включение в задачи предварительного обучения CS повышает метрики более чем на 4 балла, демонстрируя, что этот подход также способен к генерализации за пределами семантического следования.

![Accuracy](https://habrastorage.org/webt/g5/oa/w8/g5oaw87igxp4kec797cutsaq_uw.png)

*Результаты на TabFact (**слева**) и SQA (**справа**). Используя синтетические наборы данных и наборы контрфактических данных, авторы с большим отрывом достигают наивысших метрик в обеих задачах.*

# Данные и эффективность вычислений

Другой аспект контрфактической и синтетической задач предварительного обучения заключается в том, что, поскольку модели уже обучены для двоичной классификации, их можно применять без какой-либо тонкой настройки на TabFact. Авторы исследуют, что происходит с каждой из моделей при обучении только на поднаборе данных (или даже без них). Не увидев ни одного обучающего пример, модель TAPAS + CS способна соперничать с сильной базовой моделью Table-Bert, а при обучении всего на 10% данных, результаты становятся сопоставимы с предыдущими наивысшими метриками для этой задачи.

![image7](https://habrastorage.org/webt/0z/ud/hb/0zudhbwxukcjcrqagutz4icwyvq.png)

*Точность (Accuracy) на валидационном наборе данных в зависимости от объема обучающих примеров*

Общей проблемой при попытке использовать для работы с таблицами большие модели, подобные этой, является то, что высокие вычислительные требования могут затруднить анализ очень больших таблиц. Для решения этой проблемы авторы исследуют возможность эвристически выбрать подмножества входных данных для использования в модели, чтобы оптимизировать ее вычислительную эффективность.

Авторами статьи было проведено систематическое исследование различных подходов к фильтрации входных данных, в ходе которого обнаружилось, что простые методы, которые выбирают пересечение слов в столбце таблицы и предложении, дают наилучшие результаты. Динамически выбирая, какие токены входных данных включать, можно использовать меньше ресурсов или работать с более крупными входными последовательностям. Задача состоит в том, чтобы сделать это без потери важной информации и снижения точности.

Например, все модели, описанные выше, используют последовательности из 512 токенов, что примерно соответствует обычному порогу для модели Трансформера (хотя недавние методы повышения эффективности, такие как [Reformer](https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html) или [Performer](https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html), доказали свою эффективность при масштабировании размера ввода). Предлагаемые в статье методы выбора столбцов позволяют ускорить обучение, сохраняя при этом высокую точность TabFact. Для 256 входных токенов получается очень небольшое снижение точности, но теперь модель можно предварительно обучить, дообучить на конкретную задачу и делать предсказания до двух раз быстрее. С 128 токенами модель по-прежнему превосходит предыдущую современную модель с еще более значительным ускорением - в 4 раза быстрее по всем направлениям.

![image6](https://habrastorage.org/webt/v3/a3/t0/v3a3t0hr5kcfhxy3lwzfyew20qc.png)

*Точность (Accuracy) на TabFact с использованием разной длины последовательности за счет сокращения входа с помощью предложенного метода выбора столбца.*

Используя метод выбора столбцов и новые методы предварительного обучения, появляется возможность создавать модели анализа таблиц, которым требуется меньше данных и меньшая вычислительная мощность для получения лучших результатов.

Авторы опубликовали новые модели и методы предварительного обучения в своем [репозитории на GitHub](https://github.com/google-research/tapas), где вы можете сами опробовать их в [colab](http://tiny.cc/tapas-tabfact-colab). Чтобы сделать этот подход более доступным, авторы также поделились моделями разных размеров, вплоть до «[крошечных](https://arxiv.org/abs/1908.08962)» с надеждой, что полученные результаты помогут стимулировать развитие технологий понимания табличных данных среди более широкого круга исследователей.

# Авторы

* **Автор оригинала** – Julian Eisenschlos
* **Перевод** – [Смирнова Екатерина](https://habr.com/ru/users/smekur/)
* **Редактирование и вёрстка** – [Шкарин Сергей](https://habr.com/ru/users/kouki_rus/)